# 2nd-ML100Days-
## 資料清理數據前處裡
Day001	資料分析與評估					
</br>	Day002	EDA-1/讀取資料EDA: Data summary					
</br>	Day003	3-1如何新建一個 dataframe?3-2 如何讀取其他資料? (非 csv 的資料)					
</br>	Day004	EDA: 欄位的資料類型介紹及處理					
</br>	Day005	EDA資料分佈					
</br>	Day006	EDA: Outlier 及處理					
</br>	Day007	常用的數值取代	中位數與分位數連續數值標準化				
</br>	Day008	DataFrame operationData frame merge/常用的 DataFrame 操作					
</br>	Day009	EDA: correlation/相關係數簡介					
</br>	Day010	EDA from Correlation					
</br>	Day011	EDA: 不同數值範圍間的特徵如何檢視/繪圖與樣式Kernel Density Estimation (KDE)					
</br>	Day012	EDA: 把連續型變數離散化					
</br>	Day013	程式實作 把連續型變數離散化					
</br>	Day014	Subplots					
</br>	Day015	Heatmap & Grid-plot					
</br>	Day016	模型初體驗 Logistic Regression	
## 資料科學特徵技術工程
Day017	特徵工程簡介					
</br>	Day018	特徵類型					
</br>	Day019	數值型特徵-補缺失值與標準化					
</br>	Day020	數值型特徵 - 去除離群值					
</br>	Day021	數值型特徵 - 去除偏態					
</br>	Day022	類別型特徵 - 基礎處理					
</br>	Day023	類別型特徵 - 均值編碼					
</br>	Day024	類別型特徵 - 其他進階處理					
</br>	Day025	時間型特徵					
</br>	Day026	特徵組合 - 數值與數值組合					
</br>	Day027	特徵組合 - 類別與數值組合					
</br>	Day028	特徵選擇					
</br>	Day029	特徵評估					
</br>	Day030	分類型特徵優化 - 葉編碼		
## 機器學習基礎模型建立
Day031	機器學習概論					
</br>	Day032	機器學習-流程與步驟					
</br>	Day033	機器如何學習?					
</br>	Day034	訓練/測試集切分的概念					
</br>	Day035	regression vs. classification					
</br>	Day036	評估指標選定/evaluation metrics					
</br>	Day037	regression model 介紹 - 線性迴歸/羅吉斯回歸					
</br>	Day038	regression model 程式碼撰寫					
</br>	Day039	regression model 介紹 - LASSO 回歸/ Ridge 回歸					
</br>	Day040	regression model 程式碼撰寫					
</br>	Day041	tree based model - 決策樹 (Decision Tree) 模型介紹					
</br>	Day042	tree based model - 決策樹程式碼撰寫					
</br>	Day043	tree based model - 隨機森林 (Random Forest) 介紹					
</br>	Day044	tree based model - 隨機森林程式碼撰寫					
</br>	Day045	tree based model - 梯度提升機 (Gradient Boosting Machine) 介紹					
</br>	Day046	tree based model - 梯度提升機程式碼撰寫	
## 機器學習調整參數
Day047	超參數調整與優化
</br>	Day048	Kaggle 競賽平台介紹
</br>	Day049	集成方法 : 混合泛化(Blending)
</br>	Day050	集成方法 : 堆疊泛化(Stacking)
## Day051-Day053 Midterm exam
##  非監督式機器學習
Day054	clustering 1 非監督式機器學習簡介
</br>	Day055	clustering 2 聚類算法
</br>	Day056	K-mean 觀察 : 使用輪廓分析
</br>	Day057	clustering 3 階層分群算法
</br>	Day058	階層分群法 觀察 : 使用 2D 樣版資料集
</br>	Day059	dimension reduction 1 降維方法-主成份分析
</br>	Day060	PCA 觀察 : 使用手寫辨識資料集
</br>	Day061	dimension reduction 2 降維方法-T-SNE
</br>	Day062	t-sne 觀察 : 分群與流形還原
## 深度學習理論與實作
Day063	神經網路介紹
</br>	Day064	深度學習體驗 : 模型調整與學習曲線
</br>	Day065	深度學習體驗 : 啟動函數與正規化
## 初探深度學習使用Keras
Day066	Keras 安裝與介紹
</br>	Day067	Keras Dataset
</br>	Day068	Keras Sequential API
</br>	Day069	Keras Module API
</br>	Day070	Multi-layer Perception多層感知
</br>	Day071	損失函數
</br>	Day072	啟動函數
</br>	Day073	梯度下降Gradient Descent
</br>	Day074	Gradient Descent 數學原理
</br>	Day075	BackPropagation
</br>	Day076	優化器optimizers
</br>	Day077	訓練神經網路的細節與技巧 - Validation and overfit
</br>	Day078	訓練神經網路前的注意事項
</br>	Day079	訓練神經網路的細節與技巧 - Learning rate effect
</br>	Day080	優化器與學習率的組合與比較
</br>	Day081	訓練神經網路的細節與技巧 - Regularization
</br>	Day082	訓練神經網路的細節與技巧 - Dropout
</br>	Day083	訓練神經網路的細節與技巧 - Batch normalization
</br>	Day084	規化/機移除/批次標準化的 組合與比較
</br>	Day085	訓練神經網路的細節與技巧 - 使用 callbacks 函數做 earlystop
</br>	Day086	訓練神經網路的細節與技巧 - 使用 callbacks 函數儲存 model
</br>	Day087	訓練神經網路的細節與技巧 - 使用 callbacks 函數做 reduce learning rate
</br>	Day088	訓練神經網路的細節與技巧 - 撰寫自己的 callbacks 函數
</br>	Day089	訓練神經網路的細節與技巧 - 撰寫自己的 Loss function
</br>	Day090	使用傳統電腦視覺與機器學習進行影像辨識
</br>	Day091	使用傳統電腦視覺與機器學習進行影像辨識
## 深度學習應用卷積神經網路
Day092	卷積神經網路 (Convolution Neural Network, CNN) 簡介
</br>	Day093	卷積神經網路架構細節
</br>	Day094	卷積神經網路 - 卷積(Convolution)層與參數調整
</br>	Day095	卷積神經網路 - 池化(Pooling)層與參數調整
</br>	Day096	Keras 中的 CNN layers
</br>	Day097	使用 CNN 完成 CIFAR-10 資料集
</br>	Day098	訓練卷積神經網路的細節與技巧 - 處理大量數據
</br>	Day099	訓練卷積神經網路的細節與技巧 - 處理小量數據
</br>	Day100	訓練卷積神經網路的細節與技巧 - 轉移學習 (Transfer learning)
## Day101-Day103 Final exam
## Bonus 進階補充
Day104	互動式網頁神經網路視覺化
</br>	Day105	CNN卷積網路回顧
</br>	Day106	常見影像資料集介紹 (Cifar-10, ImageNet, COCO)
</br>	Day107	電腦視覺應用介紹 - 影像分類, 影像分割, 物件偵測
